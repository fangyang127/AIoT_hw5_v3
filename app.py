import io
from typing import Optional, Tuple

import streamlit as st
from transformers import pipeline


@st.cache_resource(show_spinner=False)
def load_detector():
    """
    Cache the Hugging Face pipeline so the modelåªè¼‰å…¥ä¸€æ¬¡ã€‚
    roberta-base-openai-detector æ˜¯è¼•é‡ç´šäºŒåˆ†é¡žæ¨¡åž‹ï¼Œæ¨™ç±¤ï¼š
    - Fake: æ¨¡åž‹åˆ¤å®šç‚º AI ç”Ÿæˆ
    - Real: æ¨¡åž‹åˆ¤å®šç‚ºäººé¡žæ’°å¯«
    """
    return pipeline(
        "text-classification",
        model="roberta-base-openai-detector",
        device=-1,  # CPU
    )


def read_uploaded_file(file) -> str:
    """å°‡ä¸Šå‚³æª”æ¡ˆå…§å®¹è§£ç¢¼æˆæ–‡å­—ï¼Œå¿½ç•¥ç„¡æ³•è§£ç¢¼çš„å­—å…ƒã€‚"""
    try:
        return file.read().decode("utf-8", errors="ignore")
    except Exception:
        return ""


def predict(text: str) -> Optional[Tuple[float, float, float]]:
    """
    å›žå‚³ (ai_prob, human_prob, max_confidence)
    - ai_prob: Fake æ¨™ç±¤åˆ†æ•¸
    - human_prob: Real æ¨™ç±¤åˆ†æ•¸
    - max_confidence: æœ€é«˜åˆ†æ•¸ï¼Œç”¨æ–¼ä½Žä¿¡å¿ƒæç¤º
    """
    text = (text or "").strip()
    if not text:
        return None

    detector = load_detector()
    outputs = detector(
        text,
        truncation=True,
        max_length=512,
        return_all_scores=True,
    )[0]
    score_map = {o["label"]: float(o["score"]) for o in outputs}
    ai_prob = score_map.get("Fake", 0.0)
    human_prob = score_map.get("Real", 0.0)
    max_confidence = max(score_map.values()) if score_map else 0.0
    return ai_prob, human_prob, max_confidence


st.set_page_config(
    page_title="AI / Human æ–‡ç« åµæ¸¬å™¨",
    page_icon="ðŸ§­",
    layout="centered",
)

st.title("ðŸ§­ AI / Human æ–‡ç« åµæ¸¬å™¨")
st.write(
    "è¼¸å…¥ä¸€æ®µæ–‡æœ¬æˆ–ä¸Šå‚³æ–‡å­—æª”ï¼Œç«‹å³ä¼°è¨ˆè©²æ®µæ–‡å­—ç‚º **AI ç”Ÿæˆ** æˆ– **äººé¡žæ’°å¯«** çš„æ©ŸçŽ‡ã€‚"
)

# é è¨­æ¨£ä¾‹
sample_texts = {
    "AI ç¯„ä¾‹": (
        "Certainly! Here is a concise, well-structured overview of the requested topic. "
        "As an AI language model, I will provide bullet points, a short summary, and a "
        "polite closing statement to ensure clarity and coherence."
    ),
    "äººé¡žç¯„ä¾‹": (
        "æ˜¨å¤©åŠ ç­åˆ°åä¸€é»žï¼Œå›žå®¶è·¯ä¸Šçªç„¶ä¸‹èµ·äº†å¤§é›¨ï¼Œè·¯é‚Šæ”¤çš„è±†æ¼¿é‚„æ˜¯æº«çš„ï¼Œ"
        "å–å®Œæ‰è¦ºå¾—é€™é€±æœ«ä¸€å®šè¦è£œå€‹çœ ã€‚"
    ),
    "å­¸è¡“ç¯„ä¾‹": (
        "The experiment demonstrates that introducing a lightweight regularization term "
        "improves generalization on small datasets without significantly increasing "
        "computational cost."
    ),
}

if "input_text" not in st.session_state:
    st.session_state.input_text = ""


def load_sample(name: str):
    st.session_state.input_text = sample_texts[name]


col_left, col_right = st.columns([3, 1])
with col_left:
    st.text_area(
        "è¼¸å…¥æ–‡å­—",
        key="input_text",
        height=200,
        placeholder="è²¼ä¸Šè¦åµæ¸¬çš„å…§å®¹ï¼Œæˆ–ä½¿ç”¨å³å´ç¯„ä¾‹å¿«é€Ÿæ¸¬è©¦ã€‚",
    )
with col_right:
    st.markdown("ç¯„ä¾‹æ–‡æœ¬")
    for label in sample_texts.keys():
        st.button(f"è¼‰å…¥ {label}", on_click=load_sample, args=(label,))

uploaded_file = st.file_uploader("æˆ–ä¸Šå‚³ç´”æ–‡å­—æª” (.txt)", type=["txt"])

text_from_file = ""
if uploaded_file is not None:
    text_from_file = read_uploaded_file(uploaded_file)
    if text_from_file:
        st.success("å·²è®€å–æª”æ¡ˆå…§å®¹ï¼Œå°‡å„ªå…ˆä½¿ç”¨æª”æ¡ˆæ–‡å­—é€²è¡Œåˆ¤å®šã€‚")
    else:
        st.warning("æª”æ¡ˆå…§å®¹ç„¡æ³•è§£ç¢¼ï¼Œè«‹ç¢ºèªç‚º UTF-8 ç´”æ–‡å­—ã€‚")

st.markdown("---")

if st.button("é–‹å§‹åµæ¸¬"):
    text = text_from_file or st.session_state.input_text
    if not text.strip():
        st.warning("è«‹å…ˆè¼¸å…¥æ–‡å­—æˆ–ä¸Šå‚³æª”æ¡ˆã€‚")
    else:
        with st.spinner("æ¨¡åž‹æŽ¨è«–ä¸­ï¼Œè«‹ç¨å€™..."):
            result = predict(text)

        if result is None:
            st.error("æœªå–å¾—æœ‰æ•ˆè¼¸å…¥ï¼Œè«‹é‡è©¦ã€‚")
        else:
            ai_prob, human_prob, max_conf = result
            st.subheader("çµæžœ")
            st.write(
                f"AI ç”Ÿæˆæ©ŸçŽ‡ï¼š**{ai_prob * 100:.1f}%** | äººé¡žæ’°å¯«æ©ŸçŽ‡ï¼š**{human_prob * 100:.1f}%**"
            )

            bar_ai, bar_human = st.columns(2)
            with bar_ai:
                st.progress(ai_prob)
                st.caption("AI ç”Ÿæˆ")
            with bar_human:
                st.progress(human_prob)
                st.caption("äººé¡žæ’°å¯«")

            label = "AI ç”Ÿæˆ" if ai_prob >= human_prob else "äººé¡žæ’°å¯«"
            st.info(f"æ¨¡åž‹åˆ¤æ–·ï¼š**{label}**")

            if max_conf < 0.6:
                st.warning("æ¨¡åž‹ä¿¡å¿ƒåä½Žï¼Œçµæžœåƒ…ä¾›åƒè€ƒã€‚")

st.markdown("---")
st.caption(
    "éš±ç§æç¤ºï¼šæ‰€æœ‰æŽ¨è«–åƒ…åœ¨æœ¬åœ°ç«¯åŸ·è¡Œï¼Œä¸æœƒä¸Šå‚³æˆ–å„²å­˜æ‚¨çš„æ–‡æœ¬ã€‚è¼¸å…¥éŽçŸ­æ™‚ï¼Œæ¨¡åž‹ä¿¡å¿ƒå¯èƒ½è¼ƒä½Žã€‚"
)
